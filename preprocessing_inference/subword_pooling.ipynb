{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playing with the mask concept\n",
    "Basically only tag the first transformer token of a spacy token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import TextField\n",
    "from allennlp.data import Token\n",
    "from allennlp.data.token_indexers import PretrainedTransformerIndexer\n",
    "from allennlp.data import Batch\n",
    "from allennlp.data import Vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_json(\"valid_v1.json\", orient=\"records\", lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name=\"dccuchile/bert-base-spanish-wwm-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_ids = tokenizer(df_valid.tokens[0], is_split_into_words=True, return_offsets_mapping=True)\n",
    "allennlp_tokens = list(map(Token, tokenizer.convert_ids_to_tokens(input_ids[\"input_ids\"])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = PretrainedTransformerIndexer(model_name=model_name)\n",
    "text_field = TextField(allennlp_tokens, token_indexers={\"transformers\": indexer})\n",
    "instance = Instance({\"tokens\": text_field})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b9a19608c1c84213a36a40d753de5118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='building vocab', max=1.0, style=ProgressStyle(description…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances([instance])\n",
    "batch = Batch([instance])\n",
    "batch.index_instances(vocab)\n",
    "token_ids = batch.as_tensor_dict()[\"tokens\"][\"transformers\"]\n",
    "indices = indexer.tokens_to_indices(allennlp_tokens, vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_offsets(df, model_name=\"dccuchile/bert-base-spanish-wwm-uncased\") -> Tuple[List, List]:\n",
    "    indexer = PretrainedTransformerIndexer(model_name=model_name)\n",
    "    vocab = Vocabulary()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name) \n",
    "    \n",
    "    for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        indices = tokenizer(row.tokens, return_offsets_mapping=True, is_split_into_words=True, return_special_tokens_mask=True)\n",
    "        print\n",
    "        token_groups = []\n",
    "        for input_id, offset in zip(indices[\"input_ids\"][1:-1], indices[\"offset_mapping\"][1:-1]):\n",
    "            if offset[0] == 0:\n",
    "                token_groups.append([tokenizer.convert_ids_to_tokens(input_id)])\n",
    "            else:\n",
    "                token_groups[-1].append(tokenizer.convert_ids_to_tokens(input_id))\n",
    "        print(list(zip(row.tokens, token_groups)))\n",
    "        tokens_str = tokenizer.convert_ids_to_tokens(indices[\"input_ids\"])\n",
    "        tokens = [Token(tok) for tok in tokens_str]\n",
    "        token_indexes = indexer.tokens_to_indices(tokens, vocabulary=vocab)\n",
    "        token_ids = token_indexes[\"token_ids\"]\n",
    "                    \n",
    "    return destroyed_tokens, destroyed_tags, offs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bf2bd91dc4347a29ab43950a2e07dd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('COMUNICADO', ['comunicado']), ('POR', ['por']), ('CORONAVIRUS', ['corona', '##vir', '##us']), ('\\n', ['el']), ('El', ['presidente']), ('Presidente', ['ruso']), ('Ruso', ['vladimir']), ('Vladimir', ['pu', '##tin']), ('Putin', ['ha']), ('ha', ['dicho']), ('dicho', [':']), (':', ['\"']), ('\"', ['los']), ('los', ['ciudadanos']), ('ciudadanos', ['rusos']), ('rusos', ['tienen']), ('tienen', ['dos']), ('dos', ['opciones']), ('opciones', [',']), (',', ['se']), ('se', ['quedan']), ('quedan', ['en']), ('en', ['su']), ('su', ['casa']), ('casa', ['por']), ('por', ['15']), ('15', ['dias']), ('días', ['o']), ('o', ['van']), ('van', ['a']), ('a', ['prision']), ('prisión', ['por']), ('por', ['5']), ('5', ['anos']), ('años', ['\"']), ('\"', ['fin']), ('FIN', ['del']), ('DEL', ['comunicado']), ('COMUNICADO', ['.']), ('.', ['[UNK]']), (' ', ['nom', '##e', '##que', '##do', '##en', '##cas', '##a']), ('#', ['h', '##tt', '##ps', ':', '[UNK]', '[UNK]', 't', '.', 'co', '[UNK]', 'z', '##ml', '##w', '##un', '##v', '##s', '##8', '##0'])]\n",
      "[('“', ['[UNK]']), ('La', ['la']), ('falta', ['falta']), ('de', ['de']), ('transparencia', ['transparencia']), ('en', ['en']), ('asuntos', ['asuntos']), ('de', ['de']), ('salud', ['salud']), ('pública', ['publica']), ('tendría', ['tendr', '##ia']), ('que', ['que']), ('ser', ['ser']), ('un', ['un']), ('crimen', ['crimen']), ('de', ['de']), ('lesa', ['lesa']), ('humanidad', ['humanidad']), ('.', ['.']), (' ', ['esto']), ('Esto', ['nos']), ('nos', ['demuestra']), ('demuestra', ['que']), ('que', ['los']), ('los', ['reg', '##imen', '##es']), ('regímenes', ['autor', '##itarios']), ('autoritarios', ['y']), ('y', ['herm', '##et', '##icos']), ('herméticos', ['son']), ('son', ['un']), ('un', ['peligro']), ('peligro', ['para']), ('para', ['la']), ('la', ['salud']), ('salud', ['y']), ('y', ['la']), ('la', ['paz']), ('paz', ['mundial']), ('mundial', ['[UNK]']), ('”', ['.', '.', '.'])]\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'destroyed_tokens' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-2a1a5d2aa9d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcheck_offsets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_valid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-49-84bda4d38a30>\u001b[0m in \u001b[0;36mcheck_offsets\u001b[0;34m(df, model_name)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mtoken_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtoken_indexes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"token_ids\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdestroyed_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestroyed_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'destroyed_tokens' is not defined"
     ]
    }
   ],
   "source": [
    "check_offsets(df_valid[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biome.text import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset json (/home/david/.cache/huggingface/datasets/json/default-b2dd006bd782a885/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n"
     ]
    }
   ],
   "source": [
    "ds = Dataset.from_json(\"valid_v1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices = tokenizer(ds[0][\"tokens\"], return_offsets_mapping=True, is_split_into_words=True, return_special_tokens_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i = 0\n",
    "for off in indices[\"offset_mapping\"]:\n",
    "    if off[0] == 0:\n",
    "        i += 1\n",
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ds[0][\"tags_bio\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.metrics import SpanBasedF1Measure\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1 = SpanBasedF1Measure(Vocabulary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = [[\"B-TEST\", \"I-TEST\", \"O\"], ...]\n",
    "gold = [\"B-TEST\", \"O\", \"O\"]\n",
    "vocab = {\"B-TEST\": 0, \"I-TEST\": 1, \"O\": 2}\n",
    "\n",
    "vocab = {\"B-8474693\", \"I-...\", ...........}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgold_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           SpanBasedF1Measure\n",
       "\u001b[0;31mString form:\u001b[0m    <allennlp.training.metrics.span_based_f1_measure.SpanBasedF1Measure object at 0x7f712113e6d0>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/biome/lib/python3.7/site-packages/allennlp/training/metrics/span_based_f1_measure.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The Conll SRL metrics are based on exact span matching. This metric\n",
       "implements span-based precision and recall metrics for a BIO tagging\n",
       "scheme. It will produce precision, recall and F1 measures per tag, as\n",
       "well as overall statistics. Note that the implementation of this metric\n",
       "is not exactly the same as the perl script used to evaluate the CONLL 2005\n",
       "data - particularly, it does not consider continuations or reference spans\n",
       "as constituents of the original span. However, it is a close proxy, which\n",
       "can be helpful for judging model performance during training. This metric\n",
       "works properly when the spans are unlabeled (i.e., your labels are\n",
       "simply \"B\", \"I\", \"O\" if using the \"BIO\" label encoding).\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "# Parameters\n",
       "\n",
       "vocabulary : `Vocabulary`, required.\n",
       "    A vocabulary containing the tag namespace.\n",
       "\n",
       "tag_namespace : `str`, required.\n",
       "    This metric assumes that a BIO format is used in which the\n",
       "    labels are of the format: [\"B-LABEL\", \"I-LABEL\"].\n",
       "\n",
       "ignore_classes : `List[str]`, optional.\n",
       "    Span labels which will be ignored when computing span metrics.\n",
       "    A \"span label\" is the part that comes after the BIO label, so it\n",
       "    would be \"ARG1\" for the tag \"B-ARG1\". For example by passing:\n",
       "\n",
       "     `ignore_classes=[\"V\"]`\n",
       "    the following sequence would not consider the \"V\" span at index (2, 3)\n",
       "    when computing the precision, recall and F1 metrics.\n",
       "\n",
       "    [\"O\", \"O\", \"B-V\", \"I-V\", \"B-ARG1\", \"I-ARG1\"]\n",
       "\n",
       "    This is helpful for instance, to avoid computing metrics for \"V\"\n",
       "    spans in a BIO tagging scheme which are typically not included.\n",
       "\n",
       "label_encoding : `str`, optional (default = `\"BIO\"`)\n",
       "    The encoding used to specify label span endpoints in the sequence.\n",
       "    Valid options are \"BIO\", \"IOB1\", \"BIOUL\" or \"BMES\".\n",
       "\n",
       "tags_to_spans_function : `Callable`, optional (default = `None`)\n",
       "    If `label_encoding` is `None`, `tags_to_spans_function` will be\n",
       "    used to generate spans.\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "# Parameters\n",
       "\n",
       "predictions : `torch.Tensor`, required.\n",
       "    A tensor of predictions of shape (batch_size, sequence_length, num_classes).\n",
       "gold_labels : `torch.Tensor`, required.\n",
       "    A tensor of integer class label of shape (batch_size, sequence_length). It must be the same\n",
       "    shape as the `predictions` tensor without the `num_classes` dimension.\n",
       "mask : `torch.BoolTensor`, optional (default = `None`).\n",
       "    A masking tensor the same size as `gold_labels`.\n",
       "prediction_map : `torch.Tensor`, optional (default = `None`).\n",
       "    A tensor of size (batch_size, num_classes) which provides a mapping from the index of predictions\n",
       "    to the indices of the label vocabulary. If provided, the output label at each timestep will be\n",
       "    `vocabulary.get_index_to_token_vocabulary(prediction_map[batch, argmax(predictions[batch, t]))`,\n",
       "    rather than simply `vocabulary.get_index_to_token_vocabulary(argmax(predictions[batch, t]))`.\n",
       "    This is useful in cases where each Instance in the dataset is associated with a different possible\n",
       "    subset of labels from a large label-space (IE FrameNet, where each frame has a different set of\n",
       "    possible roles associated with it).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = torch.tensor([[[1, 0, 0], [0, 1, 0], [0, 0, 1]], [...], [...]]) \n",
    "gold = torch.tensor([[[1, 0, 0], [0, 0, 1], [0, 0, 1]]])\n",
    "\n",
    "len(predictions.size()) == 3\n",
    "# batchsize, nr of words, nr of labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mSignature:\u001b[0m     \n",
       "\u001b[0mf1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mpredictions\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mgold_labels\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mmask\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBoolTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mprediction_map\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mType:\u001b[0m           SpanBasedF1Measure\n",
       "\u001b[0;31mString form:\u001b[0m    <allennlp.training.metrics.span_based_f1_measure.SpanBasedF1Measure object at 0x7f7121209e90>\n",
       "\u001b[0;31mFile:\u001b[0m           ~/miniconda3/envs/biome/lib/python3.7/site-packages/allennlp/training/metrics/span_based_f1_measure.py\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "The Conll SRL metrics are based on exact span matching. This metric\n",
       "implements span-based precision and recall metrics for a BIO tagging\n",
       "scheme. It will produce precision, recall and F1 measures per tag, as\n",
       "well as overall statistics. Note that the implementation of this metric\n",
       "is not exactly the same as the perl script used to evaluate the CONLL 2005\n",
       "data - particularly, it does not consider continuations or reference spans\n",
       "as constituents of the original span. However, it is a close proxy, which\n",
       "can be helpful for judging model performance during training. This metric\n",
       "works properly when the spans are unlabeled (i.e., your labels are\n",
       "simply \"B\", \"I\", \"O\" if using the \"BIO\" label encoding).\n",
       "\u001b[0;31mInit docstring:\u001b[0m\n",
       "# Parameters\n",
       "\n",
       "vocabulary : `Vocabulary`, required.\n",
       "    A vocabulary containing the tag namespace.\n",
       "\n",
       "tag_namespace : `str`, required.\n",
       "    This metric assumes that a BIO format is used in which the\n",
       "    labels are of the format: [\"B-LABEL\", \"I-LABEL\"].\n",
       "\n",
       "ignore_classes : `List[str]`, optional.\n",
       "    Span labels which will be ignored when computing span metrics.\n",
       "    A \"span label\" is the part that comes after the BIO label, so it\n",
       "    would be \"ARG1\" for the tag \"B-ARG1\". For example by passing:\n",
       "\n",
       "     `ignore_classes=[\"V\"]`\n",
       "    the following sequence would not consider the \"V\" span at index (2, 3)\n",
       "    when computing the precision, recall and F1 metrics.\n",
       "\n",
       "    [\"O\", \"O\", \"B-V\", \"I-V\", \"B-ARG1\", \"I-ARG1\"]\n",
       "\n",
       "    This is helpful for instance, to avoid computing metrics for \"V\"\n",
       "    spans in a BIO tagging scheme which are typically not included.\n",
       "\n",
       "label_encoding : `str`, optional (default = `\"BIO\"`)\n",
       "    The encoding used to specify label span endpoints in the sequence.\n",
       "    Valid options are \"BIO\", \"IOB1\", \"BIOUL\" or \"BMES\".\n",
       "\n",
       "tags_to_spans_function : `Callable`, optional (default = `None`)\n",
       "    If `label_encoding` is `None`, `tags_to_spans_function` will be\n",
       "    used to generate spans.\n",
       "\u001b[0;31mCall docstring:\u001b[0m\n",
       "# Parameters\n",
       "\n",
       "predictions : `torch.Tensor`, required.\n",
       "    A tensor of predictions of shape (batch_size, sequence_length, num_classes).\n",
       "gold_labels : `torch.Tensor`, required.\n",
       "    A tensor of integer class label of shape (batch_size, sequence_length). It must be the same\n",
       "    shape as the `predictions` tensor without the `num_classes` dimension.\n",
       "mask : `torch.BoolTensor`, optional (default = `None`).\n",
       "    A masking tensor the same size as `gold_labels`.\n",
       "prediction_map : `torch.Tensor`, optional (default = `None`).\n",
       "    A tensor of size (batch_size, num_classes) which provides a mapping from the index of predictions\n",
       "    to the indices of the label vocabulary. If provided, the output label at each timestep will be\n",
       "    `vocabulary.get_index_to_token_vocabulary(prediction_map[batch, argmax(predictions[batch, t]))`,\n",
       "    rather than simply `vocabulary.get_index_to_token_vocabulary(argmax(predictions[batch, t]))`.\n",
       "    This is useful in cases where each Instance in the dataset is associated with a different possible\n",
       "    subset of labels from a large label-space (IE FrameNet, where each frame has a different set of\n",
       "    possible roles associated with it).\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "f1(predictions, gold, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
