{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n",
    "\n",
    "This notebook produces the output required for a submission to the competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biome.text import Pipeline, Dataset\n",
    "from typing import List, Dict\n",
    "from helper import get_custom_tokenizer_v1\n",
    "from spacy.gold import offsets_from_biluo_tags\n",
    "from allennlp.data.dataset_readers.dataset_utils.span_utils import to_bioul\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import glob\n",
    "import spacy\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_pretrained(\"../experiments/still_plasma_32_model.tar.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification_labels': ['0', '1'],\n",
       " 'classification_probabilities': [0.9994658827781677, 0.0005341034848242998],\n",
       " 'ner_tags': ['O', 'O']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict([\"test\", \"this\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess input data\n",
    "\n",
    "Apply the same preprocessing as we did for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = get_custom_tokenizer_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_tokenizer = AutoTokenizer.from_pretrained('dccuchile/bert-base-spanish-wwm-cased') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_files = list(map(Path, sorted(glob.glob(\"../raw_data/subtask-2/brat/valid/*.txt\"))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_dataset(\n",
    "    txt_files: List[Path], \n",
    "    nlp: spacy.language.Language, \n",
    "    replace_antibert_token_with: str = None, \n",
    "    bert_tokenizer: \"transformers.AutoTokenizer\" = None\n",
    "):\n",
    "    data = {\n",
    "        \"raw_text\": [],\n",
    "        \"tokens\": [],\n",
    "        \"file_name\": [],\n",
    "    }\n",
    "    \n",
    "    for txt in tqdm(txt_files, total=len(txt_files)):\n",
    "        doc = nlp(txt.read_text())\n",
    "\n",
    "        tokens_str = list(map(str, doc))\n",
    "        if replace_antibert_token_with is not None:\n",
    "            for i, token in enumerate(tokens_str):\n",
    "                input_ids = bert_tokenizer([token], is_split_into_words=True)[\"input_ids\"]\n",
    "                if len(input_ids) <= 2:\n",
    "                    tokens_str[i] = replace_antibert_token_with\n",
    "\n",
    "        data[\"raw_text\"].append(doc.text)\n",
    "        data[\"tokens\"].append(tokens_str)\n",
    "        data[\"file_name\"].append(txt.name)\n",
    "        \n",
    "    return Dataset.from_dict(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80dee1498fe94b61a156735074b27c14",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = get_inference_dataset(\n",
    "    txt_files,\n",
    "    nlp,\n",
    "    replace_antibert_token_with=\"Ã¦\",\n",
    "    bert_tokenizer=bert_tokenizer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dad2d02235c64393b1c53faa43cca4fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=63.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_prediction(tokens_list):\n",
    "    batch = [{\"tokens\": tokens} for tokens in tokens_list]\n",
    "    return {\"predictions\": pipeline.predict(batch=batch)}\n",
    "    \n",
    "dataset = dataset.map(batch_prediction, input_columns=\"tokens\", batched=True, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'classification_labels': ['1', '0'],\n",
       " 'classification_probabilities': [0.9983344674110413, 0.0016655727522447705],\n",
       " 'ner_tags': ['O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'B-PROFESION',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O',\n",
       "  'O']}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"predictions\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0168735139ee42fcb4bb7d508e4359c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_classification_output(file_names: List[str], predictions: List[Dict]):\n",
    "    return {\n",
    "        \"tweet_id\": [file_name.split('.')[0] for file_name in file_names],\n",
    "        \"label\": [prediction[\"classification_labels\"][0] for prediction in predictions],                 \n",
    "    }\n",
    "    \n",
    "ds = dataset.map(\n",
    "    batch_classification_output,\n",
    "    input_columns=[\"file_name\", \"predictions\"],\n",
    "    batched=True,\n",
    "    batch_size=2,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242407018465579008</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242486580222103554</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242506188555718656</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242686975943094273</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242726918132301825</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>1293545412066975744</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>1293561267601510402</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>1293579520000368640</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1293598083545214980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>1293647654359117827</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows Ã 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 tweet_id label\n",
       "0     1242407018465579008     1\n",
       "1     1242486580222103554     0\n",
       "2     1242506188555718656     0\n",
       "3     1242686975943094273     1\n",
       "4     1242726918132301825     0\n",
       "...                   ...   ...\n",
       "1995  1293545412066975744     0\n",
       "1996  1293561267601510402     0\n",
       "1997  1293579520000368640     0\n",
       "1998  1293598083545214980     0\n",
       "1999  1293647654359117827     0\n",
       "\n",
       "[2000 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.head(n=None)[[\"tweet_id\", \"label\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"classification.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!cat test.tsv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NER output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = get_custom_tokenizer_v1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a6c3cd7092741f7a1b095b9a88f0776",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def batch_ner_output(file_names: List[str], raw_text: List[str], predictions: List[Dict]):\n",
    "    docs = [nlp(text) for text in raw_text]\n",
    "    bioul_tags = [to_bioul(prediction[\"ner_tags\"]) for prediction in predictions]\n",
    "    batch_offsets = [offsets_from_biluo_tags(doc, entities) for doc, entities in zip(docs, bioul_tags)]\n",
    "    tweet_ids = [file_name.split('.')[0] for file_name in file_names]\n",
    "    \n",
    "    tweet_id, begin, end, ent_type, extraction = [], [], [], [], []\n",
    "    for tid, offsets, text in zip(tweet_ids, batch_offsets, raw_text):\n",
    "        tweet_id += [tid]*len(offsets)\n",
    "        begin += [offset[0] for offset in offsets]\n",
    "        end += [offset[1] for offset in offsets]\n",
    "        ent_type += [offset[2] for offset in offsets]\n",
    "        extraction += [text[offset[0]:offset[1]] for offset in offsets]\n",
    "    \n",
    "    if any(['\\n' in ext for ext in extraction]):\n",
    "        print(\"Found 'newline' in extraction!!\")\n",
    "    \n",
    "    return {\n",
    "        \"tweet_id\": tweet_id,\n",
    "        \"begin\":begin,\n",
    "        \"end\": end,\n",
    "        \"type\":ent_type,\n",
    "        \"extraction\": extraction,\n",
    "    }\n",
    "    \n",
    "ds = dataset.map(\n",
    "    batch_ner_output,\n",
    "    input_columns=[\"file_name\", \"raw_text\", \"predictions\"],\n",
    "    batched=True,\n",
    "    batch_size=2,\n",
    "    remove_columns=dataset.column_names\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>begin</th>\n",
       "      <th>end</th>\n",
       "      <th>type</th>\n",
       "      <th>extraction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1242407018465579008</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>Presidente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1242686975943094273</td>\n",
       "      <td>192</td>\n",
       "      <td>208</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>guardias civiles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1242742067501174785</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>MÃ©dicos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1242797453423841281</td>\n",
       "      <td>3</td>\n",
       "      <td>20</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>ex vicepresidente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1242813220416565250</td>\n",
       "      <td>34</td>\n",
       "      <td>38</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>juez</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684</th>\n",
       "      <td>1292023343105937408</td>\n",
       "      <td>62</td>\n",
       "      <td>72</td>\n",
       "      <td>SITUACION_LABORAL</td>\n",
       "      <td>trabajador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>1292023343105937408</td>\n",
       "      <td>102</td>\n",
       "      <td>114</td>\n",
       "      <td>SITUACION_LABORAL</td>\n",
       "      <td>#teletrabajo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>1292408137010548737</td>\n",
       "      <td>32</td>\n",
       "      <td>42</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>reporteros</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>1292978140579532801</td>\n",
       "      <td>91</td>\n",
       "      <td>99</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>expertos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>1293136393133346816</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>PROFESION</td>\n",
       "      <td>presidente</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>689 rows Ã 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                tweet_id  begin  end               type         extraction\n",
       "0    1242407018465579008     31   41          PROFESION         Presidente\n",
       "1    1242686975943094273    192  208          PROFESION   guardias civiles\n",
       "2    1242742067501174785      0    7          PROFESION            MÃ©dicos\n",
       "3    1242797453423841281      3   20          PROFESION  ex vicepresidente\n",
       "4    1242813220416565250     34   38          PROFESION               juez\n",
       "..                   ...    ...  ...                ...                ...\n",
       "684  1292023343105937408     62   72  SITUACION_LABORAL         trabajador\n",
       "685  1292023343105937408    102  114  SITUACION_LABORAL       #teletrabajo\n",
       "686  1292408137010548737     32   42          PROFESION         reporteros\n",
       "687  1292978140579532801     91   99          PROFESION           expertos\n",
       "688  1293136393133346816      3   13          PROFESION         presidente\n",
       "\n",
       "[689 rows x 5 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = ds.head(n=None)[[\"tweet_id\", \"begin\", \"end\", \"type\", \"extraction\"]]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"ner.tsv\", sep=\"\\t\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
