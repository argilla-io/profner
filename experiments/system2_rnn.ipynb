{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install stuff on Colab and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zueqb8izumpD",
    "outputId": "df2d8ada-296d-47b5-bf98-7309f036d9ef"
   },
   "outputs": [],
   "source": [
    "#!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "s1hJbMuKudVL",
    "outputId": "65884c30-1d4a-4e15-b9ea-9b0778410f96"
   },
   "outputs": [],
   "source": [
    "# In case you want to run it on Google Colab, don't forget to install biome.text first\n",
    "\n",
    "# !pip install -U pip\n",
    "# !pip install -U git+https://github.com/recognai/biome-text.git@project/profner\n",
    "# exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eFoFiT9luq37",
    "outputId": "a10ddb33-289d-4d9b-d542-48ac37f4fe47"
   },
   "outputs": [],
   "source": [
    "# !pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Pk-bNMeKvRt-",
    "outputId": "3ac3d88f-a74d-4dfa-8bc2-18ddfb7edf2e"
   },
   "outputs": [],
   "source": [
    "# !wandb login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "y97I_QIlveeB"
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "from biome.text import Dataset, Pipeline, TrainerConfiguration\n",
    "from biome.text.hpo import TuneExperiment\n",
    "from ray import tune\n",
    "from ray.tune.suggest.hyperopt import HyperOptSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create training and validation data sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nPqP3AHpvl-V",
    "outputId": "980d5662-4d8d-47d8-89d1-6b2cc65ea845"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f04e753e48147d1a3d41313aeabcf45",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1202.0, style=ProgressStyle(description‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default-6bacbcbff55d5326 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/david/.cache/huggingface/datasets/json/default-6bacbcbff55d5326/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/david/.cache/huggingface/datasets/json/default-6bacbcbff55d5326/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset json/default-b2dd006bd782a885 (download: Unknown size, generated: Unknown size, post-processed: Unknown size, total: Unknown size) to /home/david/.cache/huggingface/datasets/json/default-b2dd006bd782a885/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', layout=Layout(width='20px'), max=1.0), HTML(value=''‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset json downloaded and prepared to /home/david/.cache/huggingface/datasets/json/default-b2dd006bd782a885/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514. Subsequent calls will reuse this data.\n"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset.from_json(\"../preprocessing_inference/train_v1.json\")\n",
    "valid_ds = Dataset.from_json(\"../preprocessing_inference/valid_v1.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "9F2Gszk2vo6n"
   },
   "outputs": [],
   "source": [
    "train_ds.rename_column_(\"tags_bio\", \"tags\")\n",
    "valid_ds.rename_column_(\"tags_bio\", \"tags\")\n",
    "train_ds.rename_column_(\"classification_label\", \"labels\")\n",
    "valid_ds.rename_column_(\"classification_label\", \"labels\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_bioul</th>\n",
       "      <th>tags</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>labels</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cerramos nuestra querida Radio üò¢ Nuestros cola...</td>\n",
       "      <td>[Cerramos, nuestra, querida, Radio, üò¢, Nuestro...</td>\n",
       "      <td>[O, O, O, O, O, O, U-PROFESION, O, U-PROFESION...</td>\n",
       "      <td>[O, O, O, O, O, O, B-PROFESION, O, B-PROFESION...</td>\n",
       "      <td>[colaboradores, conductores]</td>\n",
       "      <td>1</td>\n",
       "      <td>1242399976644325376.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#OtroEscandalo #HastaCuando \\n#DenunciaCCOO #C...</td>\n",
       "      <td>[#, OtroEscandalo, #, HastaCuando, \\n, #, Denu...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242406334802395137.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¬øEs necesario entregar nuestra privacidad a un...</td>\n",
       "      <td>[¬ø, Es, necesario, entregar, nuestra, privacid...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242407077278093313.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As√≠ que est√°s chimbeando mucho con esos Decret...</td>\n",
       "      <td>[As√≠, que, est√°s, chimbeando, mucho, con, esos...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, U-PROFESION,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PROFESION,...</td>\n",
       "      <td>[Presidente]</td>\n",
       "      <td>1</td>\n",
       "      <td>1242407274771030016.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@FeGarPe79 @escipion_r @LuciaMendezEM Est√°s MU...</td>\n",
       "      <td>[@FeGarPe79, @escipion_r, @LuciaMendezEM, Est√°...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242409866515435520.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La Generalitat facilitar√° las videconferencias...</td>\n",
       "      <td>[La, Generalitat, facilitar√°, las, videconfere...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242420050167988227.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>‚ÄúEl p√°nico por coronavirus es injustificado‚Äù d...</td>\n",
       "      <td>[‚Äú, El, p√°nico, por, coronavirus, es, injustif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, U-PROFESION, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PROFESION, O,...</td>\n",
       "      <td>[vir√≥logo]</td>\n",
       "      <td>1</td>\n",
       "      <td>1242429168505233410.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La transparencia es necesaria para luchar cont...</td>\n",
       "      <td>[La, transparencia, es, necesaria, para, lucha...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242448823810654209.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ojo con los mensajes que se est√°n lanzando des...</td>\n",
       "      <td>[Ojo, con, los, mensajes, que, se, est√°n, lanz...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242501570824200194.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>¬øDispones de fundas de pl√°stico cubreasientos ...</td>\n",
       "      <td>[¬ø, Dispones, de, fundas, de, pl√°stico, cubrea...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242506209506312193.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  \\\n",
       "0  Cerramos nuestra querida Radio üò¢ Nuestros cola...   \n",
       "1  #OtroEscandalo #HastaCuando \\n#DenunciaCCOO #C...   \n",
       "2  ¬øEs necesario entregar nuestra privacidad a un...   \n",
       "3  As√≠ que est√°s chimbeando mucho con esos Decret...   \n",
       "4  @FeGarPe79 @escipion_r @LuciaMendezEM Est√°s MU...   \n",
       "5  La Generalitat facilitar√° las videconferencias...   \n",
       "6  ‚ÄúEl p√°nico por coronavirus es injustificado‚Äù d...   \n",
       "7  La transparencia es necesaria para luchar cont...   \n",
       "8  Ojo con los mensajes que se est√°n lanzando des...   \n",
       "9  ¬øDispones de fundas de pl√°stico cubreasientos ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Cerramos, nuestra, querida, Radio, üò¢, Nuestro...   \n",
       "1  [#, OtroEscandalo, #, HastaCuando, \\n, #, Denu...   \n",
       "2  [¬ø, Es, necesario, entregar, nuestra, privacid...   \n",
       "3  [As√≠, que, est√°s, chimbeando, mucho, con, esos...   \n",
       "4  [@FeGarPe79, @escipion_r, @LuciaMendezEM, Est√°...   \n",
       "5  [La, Generalitat, facilitar√°, las, videconfere...   \n",
       "6  [‚Äú, El, p√°nico, por, coronavirus, es, injustif...   \n",
       "7  [La, transparencia, es, necesaria, para, lucha...   \n",
       "8  [Ojo, con, los, mensajes, que, se, est√°n, lanz...   \n",
       "9  [¬ø, Dispones, de, fundas, de, pl√°stico, cubrea...   \n",
       "\n",
       "                                          tags_bioul  \\\n",
       "0  [O, O, O, O, O, O, U-PROFESION, O, U-PROFESION...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, U-PROFESION,...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "6  [O, O, O, O, O, O, O, O, O, O, U-PROFESION, O,...   \n",
       "7  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "8  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "9  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                                tags  \\\n",
       "0  [O, O, O, O, O, O, B-PROFESION, O, B-PROFESION...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, B-PROFESION,...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "6  [O, O, O, O, O, O, O, O, O, O, B-PROFESION, O,...   \n",
       "7  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "8  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "9  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                    entity_text labels                file_name  \n",
       "0  [colaboradores, conductores]      1  1242399976644325376.txt  \n",
       "1                            []      0  1242406334802395137.txt  \n",
       "2                            []      0  1242407077278093313.txt  \n",
       "3                  [Presidente]      1  1242407274771030016.txt  \n",
       "4                            []      0  1242409866515435520.txt  \n",
       "5                            []      0  1242420050167988227.txt  \n",
       "6                    [vir√≥logo]      1  1242429168505233410.txt  \n",
       "7                            []      0  1242448823810654209.txt  \n",
       "8                            []      0  1242501570824200194.txt  \n",
       "9                            []      0  1242506209506312193.txt  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get pretrained word vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nyNb8uUSv2c_",
    "outputId": "13437a00-1caf-4b9b-8f40-85d6b3706ab8"
   },
   "outputs": [],
   "source": [
    "!wget https://zenodo.org/record/4449930/files/skipgram_cased.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dlozVc3HyWE2"
   },
   "outputs": [],
   "source": [
    "!tar -xzf skipgram_cased.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define pipeline/trainer config and HPO search spaces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "hpRmnri8wDi4"
   },
   "outputs": [],
   "source": [
    "# This is the config of a second HPO run, a\n",
    "# fter a first HPO run we fixed obviously better choices like:\n",
    "# the weights_file, lowercase_characters, some RNN types and num_layers\n",
    "profner = {\n",
    "    \"name\": \"profner\",\n",
    "    \"features\": {\n",
    "        \"word\": {\n",
    "            \"embedding_dim\": 300, \n",
    "            \"weights_file\": str(Path(\"./covid_19_es_twitter_skipgram_cased.zip\").absolute()),\n",
    "            \"trainable\": True,\n",
    "        },\n",
    "        'char': {\n",
    "            'embedding_dim': tune.choice([32, 64]),\n",
    "            'lowercase_characters': True,\n",
    "            'encoder': {\n",
    "                'bidirectional': True,\n",
    "                'hidden_size': tune.choice([32, 64]),\n",
    "                'num_layers': 1,\n",
    "                'type': 'gru',\n",
    "            },\n",
    "            'dropout': tune.uniform(0, 0.5),\n",
    "        },\n",
    "    },\n",
    "    \"encoder\": {\n",
    "        \"type\": tune.choice([\"gru\", \"lstm\"]),\n",
    "        \"num_layers\": 1,\n",
    "        \"bidirectional\": True,\n",
    "        \"hidden_size\": tune.choice([256, 512]),\n",
    "    },\n",
    "    \"head\": {\n",
    "        \"type\": \"ProfNer\",\n",
    "        \"classification_labels\": ['1', '0'],\n",
    "        \"classification_pooler\": {\n",
    "            \"type\": \"lstm\",\n",
    "            \"num_layers\": 1,\n",
    "            \"bidirectional\": True,\n",
    "            \"hidden_size\": tune.choice([64, 128]),\n",
    "        },\n",
    "        \"ner_feedforward\": {\n",
    "            \"activations\": [\"relu\"],\n",
    "            \"dropout\": [0],\n",
    "            \"hidden_dims\": [128],\n",
    "            \"num_layers\": 1,\n",
    "        },\n",
    "        \"ner_tags\": ['O', 'B-PROFESION', 'I-SITUACION_LABORAL', 'I-PROFESION', 'B-SITUACION_LABORAL'],\n",
    "        \"ner_tags_encoding\": \"BIO\",\n",
    "        \"dropout\": tune.uniform(0, 0.7),\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_config = dict(\n",
    "    optimizer={\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": tune.loguniform(1e-4, 1e-1),\n",
    "        \"weight_decay\": tune.loguniform(1e-3, 1e-1)\n",
    "    },\n",
    "    linear_decay=True,\n",
    "    warmup_steps=tune.randint(0, 200),\n",
    "    training_size=len(train_ds),\n",
    "    batch_size=tune.choice([8, 16, 32]),\n",
    "    num_epochs=tune.choice([4, 5, 6, 7]),\n",
    "    validation_metric=\"+valid_ner/f1-measure-overall\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Launch HPO experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "8CRqn22axZ6p"
   },
   "outputs": [],
   "source": [
    "search_alg = HyperOptSearch(metric=\"validation_valid_ner/f1-measure-overall\", mode=\"max\")\n",
    "\n",
    "# does not support integers\n",
    "# from ray.tune.suggest.bayesopt import BayesOptSearch\n",
    "# search_alg = BayesOptSearch(metric=\"validation_ner/f1-measure-overall\", mode=\"max\")\n",
    "\n",
    "# ray2.0.0 does not use the gpu ...\n",
    "# from ray.tune.suggest.hebo import HEBOSearch\n",
    "# search_alg = HEBOSearch(metric=\"validation_ner/f1-measure-overall\", mode=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5wDFDKB31Vrn",
    "outputId": "7955317d-9029-454d-e6cf-27a261ffcc31"
   },
   "outputs": [],
   "source": [
    "hpo_experiment = TuneExperiment(\n",
    "    pipeline_config=profner,\n",
    "    trainer_config=trainer_config,\n",
    "    train_dataset=train_ds,\n",
    "    valid_dataset=valid_ds,\n",
    "    name=\"profner_rnn\",\n",
    "    num_samples=1,\n",
    "    local_dir=\"tune_runs\",\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 0.33},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GkurSW_u0EM0"
   },
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    hpo_experiment,\n",
    "    config=hpo_experiment.config,\n",
    "    scheduler=tune.schedulers.ASHAScheduler(),\n",
    "    search_alg=search_alg,\n",
    "    metric=\"validation_valid_ner/f1-measure-overall\",\n",
    "    mode=\"max\",\n",
    "#     progress_reporter=tune.CLIReporter(\n",
    "#             metric_columns=[\"best_validation_valid_ner/f1-measure-overall\", \"best_validation_valid_classification/accuracy\"],\n",
    "#             parameter_columns=[\"trainer.optimizer.lr\"],\n",
    "#         ),\n",
    "    progress_reporter=tune.JupyterNotebookReporter(overwrite=True),\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ugBMOTb1A4d"
   },
   "source": [
    "# Train the best model on train+validation data set\n",
    "\n",
    "See the \"profner_rnn\" project in wandb (https://wandb.ai/dcfidalgo/profner_rnn), the runs tagged as v3. Best run: *helpful-sun-581*; 0.731, 0.938;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_full_ds = Dataset.from_datasets([train_ds, valid_ds])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profner = {\n",
    "    \"name\": \"profner\",\n",
    "    \"features\": {\n",
    "        \"word\": {\n",
    "            \"embedding_dim\": 300, \n",
    "            \"weights_file\": str(Path(\"./covid_19_es_twitter_skipgram_cased.zip\").absolute()),\n",
    "            \"trainable\": True,\n",
    "        },\n",
    "        'char': {\n",
    "            'embedding_dim': 64,\n",
    "            'lowercase_characters': True,\n",
    "            'encoder': {\n",
    "                'bidirectional': True,\n",
    "                'hidden_size': 64,\n",
    "                'num_layers': 1,\n",
    "                'type': 'gru',\n",
    "            },\n",
    "            'dropout': 0.008045582408546581\n",
    "        }\n",
    "    },\n",
    "    \"encoder\": {\n",
    "        \"type\": \"gru\",\n",
    "        \"num_layers\": 1,\n",
    "        \"bidirectional\": True,\n",
    "        \"hidden_size\": 512,\n",
    "    },\n",
    "    \"head\": {\n",
    "        \"type\": \"ProfNer\",\n",
    "        \"classification_labels\": train_ds.unique(\"labels\"),\n",
    "        \"classification_pooler\": {\n",
    "            \"type\": \"lstm\",\n",
    "            \"num_layers\": 1,\n",
    "            \"bidirectional\": True,\n",
    "            \"hidden_size\": 64,\n",
    "        },\n",
    "        \"ner_feedforward\": {\n",
    "            \"activations\": [\"relu\"],\n",
    "            \"dropout\": [0],\n",
    "            \"hidden_dims\": [128],\n",
    "            \"num_layers\": 1,\n",
    "        },\n",
    "        \"ner_tags\": list(set(itertools.chain.from_iterable(train_ds[\"tags\"]))),\n",
    "        \"ner_tags_encoding\": \"BIO\",\n",
    "        \"dropout\": 0.43890376017930377,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerConfiguration(\n",
    "    optimizer={\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": 0.0008738642587749882,\n",
    "        \"weight_decay\": 0.0015643023992246586,\n",
    "    },\n",
    "    linear_decay=True,\n",
    "    warmup_steps=113,\n",
    "    batch_size=8,\n",
    "    num_epochs=5,\n",
    "    validation_metric=\"+valid_ner/f1-measure-overall\",\n",
    "    random_seed=4,  # best value from a quick manual sweep\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_config(profner)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.train(\n",
    "    output=\"final_rnn_model\",\n",
    "    training=train_full_ds,\n",
    "    trainer=trainer,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "profner.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
