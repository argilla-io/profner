{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biome.text import Dataset, Pipeline, TrainerConfiguration\n",
    "from biome.text.hpo import TuneExperiment\n",
    "import itertools\n",
    "import os\n",
    "from ray import tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.environ[\"WANDB_PROJECT\"] = \"profner\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W&B offline, running your script from this directory will only write metadata locally.\n"
     ]
    }
   ],
   "source": [
    "!wandb offline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Reusing dataset json (/home/david/.cache/huggingface/datasets/json/default-6489373448f25f56/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n",
      "Using custom data configuration default\n",
      "Reusing dataset json (/home/david/.cache/huggingface/datasets/json/default-635e2cada6fc2ad1/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514)\n"
     ]
    }
   ],
   "source": [
    "train_ds = Dataset.from_json(\"../preprocessing_inference/train_v2.json\")\n",
    "valid_ds = Dataset.from_json(\"../preprocessing_inference/valid_v2.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>raw_text</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tags_bioul</th>\n",
       "      <th>tags_bio</th>\n",
       "      <th>entity_text</th>\n",
       "      <th>classification_label</th>\n",
       "      <th>file_name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cerramos nuestra querida Radio üò¢ Nuestros cola...</td>\n",
       "      <td>[Cerramos, nuestra, querida, Radio, üò¢, Nuestro...</td>\n",
       "      <td>[O, O, O, O, O, O, U-PROFESION, O, U-PROFESION...</td>\n",
       "      <td>[O, O, O, O, O, O, B-PROFESION, O, B-PROFESION...</td>\n",
       "      <td>[colaboradores, conductores]</td>\n",
       "      <td>1</td>\n",
       "      <td>1242399976644325376.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>#OtroEscandalo #HastaCuando \\n#DenunciaCCOO #C...</td>\n",
       "      <td>[#, OtroEscandalo, #, HastaCuando, √¶, #, Denun...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242406334802395137.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>¬øEs necesario entregar nuestra privacidad a un...</td>\n",
       "      <td>[¬ø, Es, necesario, entregar, nuestra, privacid...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242407077278093313.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>As√≠ que est√°s chimbeando mucho con esos Decret...</td>\n",
       "      <td>[As√≠, que, est√°s, chimbeando, mucho, con, esos...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, U-PROFESION,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, B-PROFESION,...</td>\n",
       "      <td>[Presidente]</td>\n",
       "      <td>1</td>\n",
       "      <td>1242407274771030016.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@FeGarPe79 @escipion_r @LuciaMendezEM Est√°s MU...</td>\n",
       "      <td>[@FeGarPe79, @escipion_r, @LuciaMendezEM, Est√°...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242409866515435520.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>La Generalitat facilitar√° las videconferencias...</td>\n",
       "      <td>[La, Generalitat, facilitar√°, las, videconfere...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242420050167988227.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>‚ÄúEl p√°nico por coronavirus es injustificado‚Äù d...</td>\n",
       "      <td>[‚Äú, El, p√°nico, por, coronavirus, es, injustif...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, U-PROFESION, O,...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, B-PROFESION, O,...</td>\n",
       "      <td>[vir√≥logo]</td>\n",
       "      <td>1</td>\n",
       "      <td>1242429168505233410.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>La transparencia es necesaria para luchar cont...</td>\n",
       "      <td>[La, transparencia, es, necesaria, para, lucha...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242448823810654209.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ojo con los mensajes que se est√°n lanzando des...</td>\n",
       "      <td>[Ojo, con, los, mensajes, que, se, est√°n, lanz...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242501570824200194.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>¬øDispones de fundas de pl√°stico cubreasientos ...</td>\n",
       "      <td>[¬ø, Dispones, de, fundas, de, pl√°stico, cubrea...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>0</td>\n",
       "      <td>1242506209506312193.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            raw_text  \\\n",
       "0  Cerramos nuestra querida Radio üò¢ Nuestros cola...   \n",
       "1  #OtroEscandalo #HastaCuando \\n#DenunciaCCOO #C...   \n",
       "2  ¬øEs necesario entregar nuestra privacidad a un...   \n",
       "3  As√≠ que est√°s chimbeando mucho con esos Decret...   \n",
       "4  @FeGarPe79 @escipion_r @LuciaMendezEM Est√°s MU...   \n",
       "5  La Generalitat facilitar√° las videconferencias...   \n",
       "6  ‚ÄúEl p√°nico por coronavirus es injustificado‚Äù d...   \n",
       "7  La transparencia es necesaria para luchar cont...   \n",
       "8  Ojo con los mensajes que se est√°n lanzando des...   \n",
       "9  ¬øDispones de fundas de pl√°stico cubreasientos ...   \n",
       "\n",
       "                                              tokens  \\\n",
       "0  [Cerramos, nuestra, querida, Radio, üò¢, Nuestro...   \n",
       "1  [#, OtroEscandalo, #, HastaCuando, √¶, #, Denun...   \n",
       "2  [¬ø, Es, necesario, entregar, nuestra, privacid...   \n",
       "3  [As√≠, que, est√°s, chimbeando, mucho, con, esos...   \n",
       "4  [@FeGarPe79, @escipion_r, @LuciaMendezEM, Est√°...   \n",
       "5  [La, Generalitat, facilitar√°, las, videconfere...   \n",
       "6  [‚Äú, El, p√°nico, por, coronavirus, es, injustif...   \n",
       "7  [La, transparencia, es, necesaria, para, lucha...   \n",
       "8  [Ojo, con, los, mensajes, que, se, est√°n, lanz...   \n",
       "9  [¬ø, Dispones, de, fundas, de, pl√°stico, cubrea...   \n",
       "\n",
       "                                          tags_bioul  \\\n",
       "0  [O, O, O, O, O, O, U-PROFESION, O, U-PROFESION...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, U-PROFESION,...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "6  [O, O, O, O, O, O, O, O, O, O, U-PROFESION, O,...   \n",
       "7  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "8  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "9  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                                            tags_bio  \\\n",
       "0  [O, O, O, O, O, O, B-PROFESION, O, B-PROFESION...   \n",
       "1  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "2  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "3  [O, O, O, O, O, O, O, O, O, O, O, B-PROFESION,...   \n",
       "4  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "5      [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O]   \n",
       "6  [O, O, O, O, O, O, O, O, O, O, B-PROFESION, O,...   \n",
       "7  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "8  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "9  [O, O, O, O, O, O, O, O, O, O, O, O, O, O, O, ...   \n",
       "\n",
       "                    entity_text classification_label                file_name  \n",
       "0  [colaboradores, conductores]                    1  1242399976644325376.txt  \n",
       "1                            []                    0  1242406334802395137.txt  \n",
       "2                            []                    0  1242407077278093313.txt  \n",
       "3                  [Presidente]                    1  1242407274771030016.txt  \n",
       "4                            []                    0  1242409866515435520.txt  \n",
       "5                            []                    0  1242420050167988227.txt  \n",
       "6                    [vir√≥logo]                    1  1242429168505233410.txt  \n",
       "7                            []                    0  1242448823810654209.txt  \n",
       "8                            []                    0  1242501570824200194.txt  \n",
       "9                            []                    0  1242506209506312193.txt  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.rename_column_(\"tags_bio\", \"tags\")\n",
    "valid_ds.rename_column_(\"tags_bio\", \"tags\")\n",
    "train_ds.rename_column_(\"classification_label\", \"labels\")\n",
    "valid_ds.rename_column_(\"classification_label\", \"labels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformers_model: str = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "#transformers_model: str = \"prajjwal1/bert-tiny\"\n",
    "\n",
    "profnert = {\n",
    "    \"name\": \"profnert\",\n",
    "    \"features\": {\n",
    "        \"transformers\": {\n",
    "            \"model_name\": transformers_model,\n",
    "            \"trainable\": True,\n",
    "        }\n",
    "    },\n",
    "    \"head\": {\n",
    "        \"type\": \"ProfNerT\",\n",
    "        \"classification_labels\": train_ds.unique(\"labels\"),\n",
    "        \"classification_pooler\": {\n",
    "            \"type\": \"bert_pooler\",\n",
    "            \"pretrained_model\": transformers_model,\n",
    "            \"requires_grad\": True,\n",
    "            \"dropout\": 0.1,\n",
    "        },\n",
    "        \"ner_tags\": list(set(itertools.chain.from_iterable(train_ds[\"tags\"]))),\n",
    "        \"ner_tags_encoding\": \"BIO\",\n",
    "        \"transformers_model\": transformers_model,\n",
    "        \"dropout\": 0.0,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_config(profnert)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerConfiguration(\n",
    "    optimizer={\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": tune.loguniform(1e-5, 1e-4),\n",
    "        \"weight_decay\": tune.loguniform(5e-3, 5e-2)\n",
    "    },\n",
    "    linear_with_warmup=True,\n",
    "    warmup_steps=tune.uniform(0, 200),\n",
    "    training_size=len(train_ds),\n",
    "    batch_size=tune.choice([4, 8, 16]),\n",
    "    num_epochs=tune.choice([3, 4, 5]),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = TuneExperiment(\n",
    "    pipeline_config=profnert,\n",
    "    trainer_config=trainer,\n",
    "    train_dataset=train_ds,\n",
    "    valid_dataset=valid_ds,\n",
    "    name=\"profner\",\n",
    "    num_samples=1,\n",
    "    local_dir=\"tune_runs\",\n",
    "    resources_per_trial={\"cpu\": 1, \"gpu\": 1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "analysis = tune.run(\n",
    "    random_search,\n",
    "    scheduler=tune.schedulers.ASHAScheduler(), \n",
    "    metric=\"validation_loss\", \n",
    "    mode=\"min\",\n",
    "    progress_reporter=tune.JupyterNotebookReporter(overwrite=True)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = TrainerConfiguration(\n",
    "    optimizer={\n",
    "        \"type\": \"adamw\",\n",
    "        \"lr\": 5e-5,\n",
    "    },\n",
    "    batch_size=4,\n",
    "    num_epochs=1,\n",
    "    cuda_device=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds.select(range(10)).to_instances(pipeline, use_cache=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds.cleanup_cache_files()\n",
    "valid_ds.cleanup_cache_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b9b3f290f34fc5ae9ca1e0aab6fcbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading instances into memory', max=6000.0, style=Progres‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 01:24:05,960 - biome.text.dataset - INFO - Caching instances to /home/david/.cache/huggingface/datasets/json/default-6489373448f25f56/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514/ef52491df94380af.instance_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d00b1fbb486943f58ee8a66c290f31ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Loading instances into memory', max=2000.0, style=Progres‚Ä¶"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 01:24:13,617 - biome.text.dataset - INFO - Caching instances to /home/david/.cache/huggingface/datasets/json/default-635e2cada6fc2ad1/0.0.0/70d89ed4db1394f028c651589fcab6d6b28dddcabbe39d3b21b4d41f9a708514/100d05899d9f80d2.instance_list)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-12 01:24:14,287 - allennlp.common.params - INFO - random_seed = 13370\n",
      "2021-02-12 01:24:14,287 - allennlp.common.params - INFO - numpy_seed = 1337\n",
      "2021-02-12 01:24:14,288 - allennlp.common.params - INFO - pytorch_seed = 133\n",
      "2021-02-12 01:24:14,314 - allennlp.common.checks - INFO - Pytorch version: 1.7.1\n",
      "2021-02-12 01:24:14,354 - allennlp.common.params - INFO - type = gradient_descent\n",
      "2021-02-12 01:24:14,355 - allennlp.common.params - INFO - local_rank = 0\n",
      "2021-02-12 01:24:14,355 - allennlp.common.params - INFO - patience = 2\n",
      "2021-02-12 01:24:14,356 - allennlp.common.params - INFO - validation_metric = -loss\n",
      "2021-02-12 01:24:14,356 - allennlp.common.params - INFO - num_epochs = 1\n",
      "2021-02-12 01:24:14,357 - allennlp.common.params - INFO - cuda_device = -1\n",
      "2021-02-12 01:24:14,358 - allennlp.common.params - INFO - grad_norm = None\n",
      "2021-02-12 01:24:14,358 - allennlp.common.params - INFO - grad_clipping = None\n",
      "2021-02-12 01:24:14,359 - allennlp.common.params - INFO - distributed = False\n",
      "2021-02-12 01:24:14,359 - allennlp.common.params - INFO - world_size = 1\n",
      "2021-02-12 01:24:14,360 - allennlp.common.params - INFO - num_gradient_accumulation_steps = 1\n",
      "2021-02-12 01:24:14,360 - allennlp.common.params - INFO - use_amp = False\n",
      "2021-02-12 01:24:14,361 - allennlp.common.params - INFO - no_grad = None\n",
      "2021-02-12 01:24:14,361 - allennlp.common.params - INFO - learning_rate_scheduler = None\n",
      "2021-02-12 01:24:14,361 - allennlp.common.params - INFO - momentum_scheduler = None\n",
      "2021-02-12 01:24:14,362 - allennlp.common.params - INFO - moving_average = None\n",
      "2021-02-12 01:24:14,362 - allennlp.common.params - INFO - batch_callbacks = None\n",
      "2021-02-12 01:24:14,363 - allennlp.common.params - INFO - end_callbacks = None\n",
      "2021-02-12 01:24:14,364 - allennlp.common.params - INFO - trainer_callbacks = None\n",
      "2021-02-12 01:24:14,365 - allennlp.common.params - INFO - optimizer.type = adamw\n",
      "2021-02-12 01:24:14,366 - allennlp.common.params - INFO - optimizer.parameter_groups = None\n",
      "2021-02-12 01:24:14,366 - allennlp.common.params - INFO - optimizer.lr = 5e-05\n",
      "2021-02-12 01:24:14,367 - allennlp.common.params - INFO - optimizer.betas = (0.9, 0.999)\n",
      "2021-02-12 01:24:14,367 - allennlp.common.params - INFO - optimizer.eps = 1e-08\n",
      "2021-02-12 01:24:14,368 - allennlp.common.params - INFO - optimizer.weight_decay = 0.01\n",
      "2021-02-12 01:24:14,368 - allennlp.common.params - INFO - optimizer.amsgrad = False\n",
      "2021-02-12 01:24:14,369 - allennlp.training.optimizers - INFO - Number of trainable parameters: 110446890\n",
      "2021-02-12 01:24:14,369 - allennlp.common.util - INFO - The following parameters are Frozen (without gradient):\n",
      "2021-02-12 01:24:14,371 - allennlp.common.util - INFO - _head._crf._constraint_mask\n",
      "2021-02-12 01:24:14,371 - allennlp.common.util - INFO - The following parameters are Tunable (with gradient):\n",
      "2021-02-12 01:24:14,372 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.embeddings.word_embeddings.weight\n",
      "2021-02-12 01:24:14,373 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.embeddings.position_embeddings.weight\n",
      "2021-02-12 01:24:14,373 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.embeddings.token_type_embeddings.weight\n",
      "2021-02-12 01:24:14,373 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.embeddings.LayerNorm.weight\n",
      "2021-02-12 01:24:14,373 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.embeddings.LayerNorm.bias\n",
      "2021-02-12 01:24:14,374 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.self.query.weight\n",
      "2021-02-12 01:24:14,375 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.self.query.bias\n",
      "2021-02-12 01:24:14,375 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.self.key.weight\n",
      "2021-02-12 01:24:14,375 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.self.key.bias\n",
      "2021-02-12 01:24:14,376 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.self.value.weight\n",
      "2021-02-12 01:24:14,376 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.self.value.bias\n",
      "2021-02-12 01:24:14,377 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,377 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,377 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,378 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,378 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,379 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,379 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.output.dense.weight\n",
      "2021-02-12 01:24:14,379 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.output.dense.bias\n",
      "2021-02-12 01:24:14,380 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,380 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,380 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.self.query.weight\n",
      "2021-02-12 01:24:14,381 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.self.query.bias\n",
      "2021-02-12 01:24:14,381 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.self.key.weight\n",
      "2021-02-12 01:24:14,381 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.self.key.bias\n",
      "2021-02-12 01:24:14,382 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.self.value.weight\n",
      "2021-02-12 01:24:14,382 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.self.value.bias\n",
      "2021-02-12 01:24:14,382 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,383 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,383 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,384 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,385 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,385 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,385 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.output.dense.weight\n",
      "2021-02-12 01:24:14,386 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.output.dense.bias\n",
      "2021-02-12 01:24:14,387 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,387 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,387 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.self.query.weight\n",
      "2021-02-12 01:24:14,388 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.self.query.bias\n",
      "2021-02-12 01:24:14,388 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.self.key.weight\n",
      "2021-02-12 01:24:14,388 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.self.key.bias\n",
      "2021-02-12 01:24:14,389 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.self.value.weight\n",
      "2021-02-12 01:24:14,389 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.self.value.bias\n",
      "2021-02-12 01:24:14,389 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,389 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,390 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,390 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,390 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,391 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,391 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.output.dense.weight\n",
      "2021-02-12 01:24:14,392 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.output.dense.bias\n",
      "2021-02-12 01:24:14,393 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,393 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.2.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,394 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.self.query.weight\n",
      "2021-02-12 01:24:14,394 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.self.query.bias\n",
      "2021-02-12 01:24:14,395 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.self.key.weight\n",
      "2021-02-12 01:24:14,395 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.self.key.bias\n",
      "2021-02-12 01:24:14,396 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.self.value.weight\n",
      "2021-02-12 01:24:14,396 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.self.value.bias\n",
      "2021-02-12 01:24:14,397 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,397 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,397 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,398 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,400 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,401 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,401 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.output.dense.weight\n",
      "2021-02-12 01:24:14,401 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.output.dense.bias\n",
      "2021-02-12 01:24:14,402 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,402 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.3.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,403 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.self.query.weight\n",
      "2021-02-12 01:24:14,403 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.self.query.bias\n",
      "2021-02-12 01:24:14,404 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.self.key.weight\n",
      "2021-02-12 01:24:14,405 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.self.key.bias\n",
      "2021-02-12 01:24:14,406 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.self.value.weight\n",
      "2021-02-12 01:24:14,406 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.self.value.bias\n",
      "2021-02-12 01:24:14,407 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,407 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,408 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,408 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,408 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,409 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,409 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.output.dense.weight\n",
      "2021-02-12 01:24:14,410 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.output.dense.bias\n",
      "2021-02-12 01:24:14,410 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,411 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.4.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,411 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.self.query.weight\n",
      "2021-02-12 01:24:14,412 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.self.query.bias\n",
      "2021-02-12 01:24:14,412 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.self.key.weight\n",
      "2021-02-12 01:24:14,412 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.self.key.bias\n",
      "2021-02-12 01:24:14,413 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.self.value.weight\n",
      "2021-02-12 01:24:14,413 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.self.value.bias\n",
      "2021-02-12 01:24:14,414 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,414 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,415 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,416 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,419 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,419 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,420 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.output.dense.weight\n",
      "2021-02-12 01:24:14,421 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.output.dense.bias\n",
      "2021-02-12 01:24:14,421 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,422 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.5.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,422 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.self.query.weight\n",
      "2021-02-12 01:24:14,422 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.self.query.bias\n",
      "2021-02-12 01:24:14,423 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.self.key.weight\n",
      "2021-02-12 01:24:14,423 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.self.key.bias\n",
      "2021-02-12 01:24:14,424 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.self.value.weight\n",
      "2021-02-12 01:24:14,424 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.self.value.bias\n",
      "2021-02-12 01:24:14,425 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,425 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,427 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,427 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,428 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,428 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,429 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.output.dense.weight\n",
      "2021-02-12 01:24:14,429 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.output.dense.bias\n",
      "2021-02-12 01:24:14,430 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,430 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.6.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,431 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.self.query.weight\n",
      "2021-02-12 01:24:14,431 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.self.query.bias\n",
      "2021-02-12 01:24:14,432 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.self.key.weight\n",
      "2021-02-12 01:24:14,432 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.self.key.bias\n",
      "2021-02-12 01:24:14,432 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.self.value.weight\n",
      "2021-02-12 01:24:14,433 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.self.value.bias\n",
      "2021-02-12 01:24:14,434 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,434 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,435 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,435 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,435 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,436 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,436 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.output.dense.weight\n",
      "2021-02-12 01:24:14,436 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.output.dense.bias\n",
      "2021-02-12 01:24:14,437 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,437 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.7.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,437 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.self.query.weight\n",
      "2021-02-12 01:24:14,438 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.self.query.bias\n",
      "2021-02-12 01:24:14,438 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.self.key.weight\n",
      "2021-02-12 01:24:14,439 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.self.key.bias\n",
      "2021-02-12 01:24:14,439 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.self.value.weight\n",
      "2021-02-12 01:24:14,439 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.self.value.bias\n",
      "2021-02-12 01:24:14,440 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,440 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,441 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,441 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,442 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,442 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,442 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.output.dense.weight\n",
      "2021-02-12 01:24:14,444 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.output.dense.bias\n",
      "2021-02-12 01:24:14,445 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,445 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.8.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,446 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.self.query.weight\n",
      "2021-02-12 01:24:14,446 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.self.query.bias\n",
      "2021-02-12 01:24:14,447 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.self.key.weight\n",
      "2021-02-12 01:24:14,447 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.self.key.bias\n",
      "2021-02-12 01:24:14,447 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.self.value.weight\n",
      "2021-02-12 01:24:14,447 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.self.value.bias\n",
      "2021-02-12 01:24:14,448 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,448 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,448 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,449 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,449 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,450 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,450 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.output.dense.weight\n",
      "2021-02-12 01:24:14,450 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.output.dense.bias\n",
      "2021-02-12 01:24:14,451 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,451 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.9.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,452 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.self.query.weight\n",
      "2021-02-12 01:24:14,452 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.self.query.bias\n",
      "2021-02-12 01:24:14,453 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.self.key.weight\n",
      "2021-02-12 01:24:14,453 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.self.key.bias\n",
      "2021-02-12 01:24:14,453 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.self.value.weight\n",
      "2021-02-12 01:24:14,454 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.self.value.bias\n",
      "2021-02-12 01:24:14,454 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,455 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,455 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,455 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,456 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,456 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,456 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.output.dense.weight\n",
      "2021-02-12 01:24:14,457 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.output.dense.bias\n",
      "2021-02-12 01:24:14,457 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,457 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.10.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,458 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.self.query.weight\n",
      "2021-02-12 01:24:14,458 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.self.query.bias\n",
      "2021-02-12 01:24:14,459 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.self.key.weight\n",
      "2021-02-12 01:24:14,459 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.self.key.bias\n",
      "2021-02-12 01:24:14,459 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.self.value.weight\n",
      "2021-02-12 01:24:14,460 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.self.value.bias\n",
      "2021-02-12 01:24:14,460 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.output.dense.weight\n",
      "2021-02-12 01:24:14,460 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.output.dense.bias\n",
      "2021-02-12 01:24:14,461 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,461 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,462 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.intermediate.dense.weight\n",
      "2021-02-12 01:24:14,462 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.intermediate.dense.bias\n",
      "2021-02-12 01:24:14,463 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.output.dense.weight\n",
      "2021-02-12 01:24:14,463 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.output.dense.bias\n",
      "2021-02-12 01:24:14,463 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.output.LayerNorm.weight\n",
      "2021-02-12 01:24:14,463 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.encoder.layer.11.output.LayerNorm.bias\n",
      "2021-02-12 01:24:14,464 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.pooler.dense.weight\n",
      "2021-02-12 01:24:14,464 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_transformers.transformer_model.pooler.dense.bias\n",
      "2021-02-12 01:24:14,465 - allennlp.common.util - INFO - _head._classification_pooler.pooler.dense.weight\n",
      "2021-02-12 01:24:14,465 - allennlp.common.util - INFO - _head._classification_pooler.pooler.dense.bias\n",
      "2021-02-12 01:24:14,466 - allennlp.common.util - INFO - _head._classification_layer.weight\n",
      "2021-02-12 01:24:14,466 - allennlp.common.util - INFO - _head._classification_layer.bias\n",
      "2021-02-12 01:24:14,466 - allennlp.common.util - INFO - _head._tag_layer._module.weight\n",
      "2021-02-12 01:24:14,467 - allennlp.common.util - INFO - _head._tag_layer._module.bias\n",
      "2021-02-12 01:24:14,467 - allennlp.common.util - INFO - _head._crf.transitions\n",
      "2021-02-12 01:24:14,468 - allennlp.common.util - INFO - _head._crf.start_transitions\n",
      "2021-02-12 01:24:14,468 - allennlp.common.util - INFO - _head._crf.end_transitions\n",
      "2021-02-12 01:24:14,469 - allennlp.common.params - INFO - checkpointer.type = default\n",
      "2021-02-12 01:24:14,469 - allennlp.common.params - INFO - checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2021-02-12 01:24:14,470 - allennlp.common.params - INFO - checkpointer.num_serialized_models_to_keep = 1\n",
      "2021-02-12 01:24:14,470 - allennlp.common.params - INFO - checkpointer.model_save_interval = None\n",
      "2021-02-12 01:24:14,471 - allennlp.common.params - INFO - tensorboard_writer.summary_interval = 100\n",
      "2021-02-12 01:24:14,471 - allennlp.common.params - INFO - tensorboard_writer.histogram_interval = None\n",
      "2021-02-12 01:24:14,472 - allennlp.common.params - INFO - tensorboard_writer.batch_size_interval = None\n",
      "2021-02-12 01:24:14,472 - allennlp.common.params - INFO - tensorboard_writer.should_log_parameter_statistics = True\n",
      "2021-02-12 01:24:14,472 - allennlp.common.params - INFO - tensorboard_writer.should_log_learning_rate = True\n",
      "2021-02-12 01:24:14,473 - allennlp.common.params - INFO - tensorboard_writer.get_batch_num_total = None\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Offline run mode, not syncing to the cloud.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: W&B syncing is set to `offline` in this directory.  Run `wandb online` to enable cloud syncing.\n",
      "2021-02-12 01:24:15,022 - allennlp.training.trainer - INFO - Beginning training.\n",
      "2021-02-12 01:24:15,023 - allennlp.training.trainer - INFO - Epoch 0/0\n",
      "2021-02-12 01:24:15,024 - allennlp.training.trainer - INFO - Worker 0 memory usage: 1.9G\n",
      "2021-02-12 01:24:15,026 - allennlp.training.trainer - INFO - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f6d3ea4195744ae5a51c691f67c68676",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=1500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pipeline.train(\n",
    "    output=\"test\",\n",
    "    training=train_ds,\n",
    "    validation=valid_ds,\n",
    "    trainer=trainer,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Å¶\n"
     ]
    }
   ],
   "source": [
    "print(u'\\u2066')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
